{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up example code\n",
    "\n",
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process import kernels\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import lapack\n",
    "from scipy import stats\n",
    "import emcee\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import src.reader as Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: prepare input pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stuff from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "RawData1 = Reader.ReadData('input/Example/Data_PHENIX_AuAu200_RAACharged_0to10_2013.dat')\n",
    "RawData2 = Reader.ReadData('input/Example/Data_PHENIX_AuAu200_RAACharged_40to50_2013.dat')\n",
    "RawData3 = Reader.ReadData('input/Example/Data_ATLAS_PbPb2760_RAACharged_0to5_2015.dat')\n",
    "RawData4 = Reader.ReadData('input/Example/Data_ATLAS_PbPb2760_RAACharged_30to40_2015.dat')\n",
    "RawData5 = Reader.ReadData('input/Example/Data_CMS_PbPb5020_RAACharged_0to10_2017.dat')\n",
    "RawData6 = Reader.ReadData('input/Example/Data_CMS_PbPb5020_RAACharged_30to50_2017.dat')\n",
    "\n",
    "# Read covariance\n",
    "# RawCov1 = Reader.ReadCovariance('input/Example/Covariance_PHENIX_AuAu200_RAACharged_0to10_2013_PHENIX_AuAu200_RAACharged_0to10_2013_SmallL.dat')\n",
    "# RawCov2 = Reader.ReadCovariance('input/Example/Covariance_PHENIX_AuAu200_RAACharged_40to50_2013_PHENIX_AuAu200_RAACharged_40to50_2013_SmallL.dat')\n",
    "# RawCov3 = Reader.ReadCovariance('input/Example/Covariance_ATLAS_PbPb2760_RAACharged_0to5_2015_ATLAS_PbPb2760_RAACharged_0to5_2015_SmallL.dat')\n",
    "# RawCov4 = Reader.ReadCovariance('input/Example/Covariance_ATLAS_PbPb2760_RAACharged_30to40_2015_ATLAS_PbPb2760_RAACharged_30to40_2015_SmallL.dat')\n",
    "# RawCov5 = Reader.ReadCovariance('input/Example/Covariance_CMS_PbPb5020_RAACharged_0to10_2017_CMS_PbPb5020_RAACharged_0to10_2017_SmallL.dat')\n",
    "# RawCov6 = Reader.ReadCovariance('input/Example/Covariance_CMS_PbPb5020_RAACharged_30to50_2017_CMS_PbPb5020_RAACharged_30to50_2017_SmallL.dat')\n",
    "\n",
    "# Read design points\n",
    "RawDesign = Reader.ReadDesign('input/Example/Design.dat')\n",
    "\n",
    "# Read model prediction\n",
    "RawPrediction1 = Reader.ReadPrediction('input/Example/Prediction_PHENIX_AuAu200_RAACharged_0to10_2013.dat')\n",
    "RawPrediction2 = Reader.ReadPrediction('input/Example/Prediction_PHENIX_AuAu200_RAACharged_40to50_2013.dat')\n",
    "RawPrediction3 = Reader.ReadPrediction('input/Example/Prediction_ATLAS_PbPb2760_RAACharged_0to5_2015.dat')\n",
    "RawPrediction4 = Reader.ReadPrediction('input/Example/Prediction_ATLAS_PbPb2760_RAACharged_30to40_2015.dat')\n",
    "RawPrediction5 = Reader.ReadPrediction('input/Example/Prediction_CMS_PbPb5020_RAACharged_0to10_2017.dat')\n",
    "RawPrediction6 = Reader.ReadPrediction('input/Example/Prediction_CMS_PbPb5020_RAACharged_30to50_2017.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this block for RHIC + LHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionary\n",
    "AllData = {}\n",
    "\n",
    "# Basic information\n",
    "AllData[\"systems\"] = [\"AuAu200\", \"PbPb2760\", \"PbPb5020\"]\n",
    "AllData[\"keys\"] = RawDesign[\"Parameter\"]\n",
    "AllData[\"labels\"] = RawDesign[\"Parameter\"]\n",
    "AllData[\"ranges\"] = [(0, 1.5), (0, 1.0), (0, 20), (0, 20), (1, 4)]\n",
    "AllData[\"observables\"] = [('R_AA', ['C0', 'C1'])]\n",
    "\n",
    "# Data points\n",
    "Data = {\"AuAu200\": {\"R_AA\": {\"C0\": RawData1[\"Data\"], \"C1\": RawData2[\"Data\"]}},\n",
    "    \"PbPb2760\": {\"R_AA\": {\"C0\": RawData3[\"Data\"], \"C1\": RawData4[\"Data\"]}},\n",
    "    \"PbPb5020\": {\"R_AA\": {\"C0\": RawData5[\"Data\"], \"C1\": RawData6[\"Data\"]}}}\n",
    "\n",
    "# Model predictions\n",
    "Prediction = {\"AuAu200\": {\"R_AA\": {\"C0\": {\"Y\": RawPrediction1[\"Prediction\"], \"x\": RawData1[\"Data\"]['x']},\n",
    "                                   \"C1\": {\"Y\": RawPrediction2[\"Prediction\"], \"x\": RawData2[\"Data\"]['x']}}},\n",
    "             \"PbPb2760\": {\"R_AA\": {\"C0\": {\"Y\": RawPrediction3[\"Prediction\"], \"x\": RawData3[\"Data\"]['x']},\n",
    "                                   \"C1\": {\"Y\": RawPrediction4[\"Prediction\"], \"x\": RawData4[\"Data\"]['x']}}},\n",
    "             \"PbPb5020\": {\"R_AA\": {\"C0\": {\"Y\": RawPrediction5[\"Prediction\"], \"x\": RawData5[\"Data\"]['x']},\n",
    "                                   \"C1\": {\"Y\": RawPrediction6[\"Prediction\"], \"x\": RawData6[\"Data\"]['x']}}}}\n",
    "\n",
    "# Covariance matrices - the indices are [system][measurement1][measurement2], each one is a block of matrix\n",
    "Covariance = Reader.InitializeCovariance(Data)\n",
    "Covariance[\"AuAu200\"][(\"R_AA\", \"C0\")][(\"R_AA\", \"C0\")] = Reader.EstimateCovariance(RawData1, RawData1, SysLength = {\"default\": 0.05})\n",
    "Covariance[\"AuAu200\"][(\"R_AA\", \"C1\")][(\"R_AA\", \"C1\")] = Reader.EstimateCovariance(RawData2, RawData2, SysLength = {\"default\": 0.10})\n",
    "Covariance[\"PbPb2760\"][(\"R_AA\", \"C0\")][(\"R_AA\", \"C0\")] = Reader.EstimateCovariance(RawData3, RawData3, SysLength = {\"default\": 0.15})\n",
    "Covariance[\"PbPb2760\"][(\"R_AA\", \"C1\")][(\"R_AA\", \"C1\")] = Reader.EstimateCovariance(RawData4, RawData4, SysLength = {\"default\": 0.20})\n",
    "Covariance[\"PbPb5020\"][(\"R_AA\", \"C0\")][(\"R_AA\", \"C0\")] = Reader.EstimateCovariance(RawData5, RawData5, SysLength = {\"default\": 0.25})\n",
    "Covariance[\"PbPb5020\"][(\"R_AA\", \"C1\")][(\"R_AA\", \"C1\")] = Reader.EstimateCovariance(RawData6, RawData6, SysLength = {\"default\": 0.30})\n",
    "\n",
    "# This is how we can add off-diagonal matrices\n",
    "# Covariance[\"PbPb5020\"][(\"R_AA\", \"C0\")][(\"R_AA\", \"C1\")] = Reader.EstimateCovariance(RawData5, RawData6, SysLength = {\"default\": 100}, SysStrength = {\"default\": 0.1})\n",
    "# Covariance[\"PbPb5020\"][(\"R_AA\", \"C1\")][(\"R_AA\", \"C0\")] = Reader.EstimateCovariance(RawData6, RawData5, SysLength = {\"default\": 100}, SysStrength = {\"default\": 0.1})\n",
    "\n",
    "# This is how we can supply external pre-generated matrices\n",
    "# Covariance[\"AuAu200\"][(\"R_AA\", \"C0\")][(\"R_AA\", \"C0\")] = RawCov1[\"Matrix\"]\n",
    "\n",
    "\n",
    "# Assign data to the dictionary\n",
    "AllData[\"design\"] = RawDesign[\"Design\"]\n",
    "AllData[\"model\"] = Prediction\n",
    "AllData[\"data\"] = Data\n",
    "AllData[\"cov\"] = Covariance\n",
    "\n",
    "# Save to the desired pickle file\n",
    "with open('input/default.p', 'wb') as handle:\n",
    "    pickle.dump(AllData, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: clean past files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean past MCMC samples\n",
    "if os.path.exists('cache/mcmc_chain.hdf'):\n",
    "    os.remove(\"cache/mcmc_chain.hdf\")\n",
    "\n",
    "# Clean past emulator\n",
    "for system in AllData[\"systems\"]:\n",
    "    if os.path.exists('cache/emulator/' + system + \".pkl\"):\n",
    "        os.remove('cache/emulator/' + system + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: run emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][emulator] training emulator for system AuAu200 (10 PC, 0 restarts)\n",
      "[ 1.5  1.  20.  20.   3. ]\n",
      "[INFO][emulator] writing cache file cache/emulator/AuAu200.pkl\n",
      "AuAu200\n",
      "10 PCs explain 0.99972 of variance\n",
      "GP 0: 0.98046 of variance, LML = 10.177, kernel: 1.95**2 * Matern(length_scale=[1.32, 4.27, 69.3, 71.7, 30], nu=1.5)\n",
      "GP 1: 0.01481 of variance, LML = -57.853, kernel: 1.29**2 * Matern(length_scale=[0.167, 10, 22.9, 27.1, 16.1], nu=1.5)\n",
      "GP 2: 0.00122 of variance, LML = -88.442, kernel: 1.07**2 * Matern(length_scale=[0.706, 0.467, 9.17, 11.5, 0.875], nu=1.5)\n",
      "GP 3: 0.00077 of variance, LML = -99.182, kernel: 1**2 * Matern(length_scale=[0.15, 0.1, 4.76, 14.9, 0.3], nu=1.5)\n",
      "GP 4: 0.00061 of variance, LML = -98.098, kernel: 0.996**2 * Matern(length_scale=[15, 0.1, 3.43, 2, 0.3], nu=1.5)\n",
      "GP 5: 0.00055 of variance, LML = -98.201, kernel: 1**2 * Matern(length_scale=[0.396, 0.276, 6.78, 4.53, 0.3], nu=1.5)\n",
      "GP 6: 0.00049 of variance, LML = -98.933, kernel: 1.01**2 * Matern(length_scale=[0.473, 0.1, 2, 4.46, 1.49], nu=1.5)\n",
      "GP 7: 0.00035 of variance, LML = -97.319, kernel: 1.02**2 * Matern(length_scale=[0.291, 0.1, 9.03, 200, 0.386], nu=1.5)\n",
      "GP 8: 0.00030 of variance, LML = -97.01, kernel: 1.04**2 * Matern(length_scale=[0.635, 0.127, 2, 200, 1.22], nu=1.5)\n",
      "GP 9: 0.00016 of variance, LML = -98.337, kernel: 1.02**2 * Matern(length_scale=[0.255, 0.1, 4.4, 12.9, 1.5], nu=1.5)\n",
      "[INFO][emulator] training emulator for system PbPb2760 (10 PC, 0 restarts)\n",
      "[ 1.5  1.  20.  20.   3. ]\n",
      "[INFO][emulator] writing cache file cache/emulator/PbPb2760.pkl\n",
      "PbPb2760\n",
      "10 PCs explain 0.99882 of variance\n",
      "GP 0: 0.98295 of variance, LML = 15.975, kernel: 2.86**2 * Matern(length_scale=[1.31, 5.54, 200, 157, 30], nu=1.5)\n",
      "GP 1: 0.00942 of variance, LML = -52.74, kernel: 2.42**2 * Matern(length_scale=[0.378, 2.56, 180, 55.9, 18.2], nu=1.5)\n",
      "GP 2: 0.00309 of variance, LML = -76.126, kernel: 1.34**2 * Matern(length_scale=[0.922, 0.657, 17.2, 23.6, 1.96], nu=1.5)\n",
      "GP 3: 0.00086 of variance, LML = -97.008, kernel: 1.01**2 * Matern(length_scale=[0.223, 0.282, 200, 3.29, 0.459], nu=1.5)\n",
      "GP 4: 0.00062 of variance, LML = -91.992, kernel: 0.997**2 * Matern(length_scale=[2.94, 1.34, 3.48, 4.21, 0.3], nu=1.5)\n",
      "GP 5: 0.00056 of variance, LML = -99.003, kernel: 1**2 * Matern(length_scale=[0.15, 0.497, 7.37, 2, 0.3], nu=1.5)\n",
      "GP 6: 0.00046 of variance, LML = -91.785, kernel: 1.08**2 * Matern(length_scale=[0.397, 10, 200, 4.69, 0.3], nu=1.5)\n",
      "GP 7: 0.00035 of variance, LML = -95.445, kernel: 0.98**2 * Matern(length_scale=[1.49, 0.138, 2, 7.7, 0.593], nu=1.5)\n",
      "GP 8: 0.00031 of variance, LML = -95.229, kernel: 1.03**2 * Matern(length_scale=[0.472, 0.131, 3.14, 200, 1.27], nu=1.5)\n",
      "GP 9: 0.00021 of variance, LML = -98.359, kernel: 1.02**2 * Matern(length_scale=[0.509, 0.1, 2.1, 200, 0.892], nu=1.5)\n",
      "[INFO][emulator] training emulator for system PbPb5020 (10 PC, 0 restarts)\n",
      "[ 1.5  1.  20.  20.   3. ]\n",
      "[INFO][emulator] writing cache file cache/emulator/PbPb5020.pkl\n",
      "PbPb5020\n",
      "10 PCs explain 0.99842 of variance\n",
      "GP 0: 0.98115 of variance, LML = 23.791, kernel: 2.8**2 * Matern(length_scale=[1.42, 5.9, 200, 181, 30], nu=1.5)\n",
      "GP 1: 0.01032 of variance, LML = -49.636, kernel: 1.5**2 * Matern(length_scale=[0.17, 10, 40.8, 75.6, 12], nu=1.5)\n",
      "GP 2: 0.00249 of variance, LML = -74.287, kernel: 1.17**2 * Matern(length_scale=[0.988, 0.611, 19.8, 18.6, 1.2], nu=1.5)\n",
      "GP 3: 0.00098 of variance, LML = -98.704, kernel: 1.01**2 * Matern(length_scale=[0.918, 0.176, 2, 11.3, 0.3], nu=1.5)\n",
      "GP 4: 0.00085 of variance, LML = -99.287, kernel: 1**2 * Matern(length_scale=[0.321, 0.189, 3.21, 2, 0.307], nu=1.5)\n",
      "GP 5: 0.00077 of variance, LML = -96.574, kernel: 0.995**2 * Matern(length_scale=[1.27, 0.123, 200, 2, 0.3], nu=1.5)\n",
      "GP 6: 0.00054 of variance, LML = -94.69, kernel: 1.02**2 * Matern(length_scale=[0.16, 0.114, 25, 200, 0.577], nu=1.5)\n",
      "GP 7: 0.00052 of variance, LML = -98.915, kernel: 1**2 * Matern(length_scale=[0.15, 0.1, 200, 4.65, 0.3], nu=1.5)\n",
      "GP 8: 0.00045 of variance, LML = -97.06, kernel: 1.02**2 * Matern(length_scale=[1.24, 0.169, 26.9, 2, 0.391], nu=1.5)\n",
      "GP 9: 0.00033 of variance, LML = -96.747, kernel: 1.07**2 * Matern(length_scale=[1.16, 0.473, 16.1, 2, 0.587], nu=1.5)\n"
     ]
    }
   ],
   "source": [
    "! /usr/local/Cellar/python/3.6.3/bin/python3 -m src.emulator --retrain --npc 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import lazydict, emulator\n",
    "EmulatorAuAu200 = emulator.Emulator.from_cache('AuAu200')\n",
    "EmulatorPbPb2760 = emulator.Emulator.from_cache('PbPb2760')\n",
    "EmulatorPbPb5020 = emulator.Emulator.from_cache('PbPb5020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: MCMC sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][mcmc] no existing chain found, starting initial burn-in\n",
      "[INFO][mcmc] running 500 walkers for 250 steps\n",
      "[INFO][mcmc] step 25: acceptance fraction: mean 0.3092, std 0.1409, min 0.0000, max 0.6400\n",
      "[INFO][mcmc] step 50: acceptance fraction: mean 0.2924, std 0.1121, min 0.0000, max 0.5400\n",
      "[INFO][mcmc] step 75: acceptance fraction: mean 0.2879, std 0.0994, min 0.0000, max 0.4933\n",
      "[INFO][mcmc] step 100: acceptance fraction: mean 0.2904, std 0.0930, min 0.0100, max 0.4700\n",
      "[INFO][mcmc] step 125: acceptance fraction: mean 0.2960, std 0.0885, min 0.0080, max 0.4640\n",
      "[INFO][mcmc] step 150: acceptance fraction: mean 0.3019, std 0.0869, min 0.0067, max 0.4667\n",
      "[INFO][mcmc] step 175: acceptance fraction: mean 0.3078, std 0.0858, min 0.0057, max 0.4800\n",
      "[INFO][mcmc] step 200: acceptance fraction: mean 0.3143, std 0.0851, min 0.0050, max 0.4700\n",
      "[INFO][mcmc] step 225: acceptance fraction: mean 0.3201, std 0.0841, min 0.0044, max 0.4667\n",
      "[INFO][mcmc] step 250: acceptance fraction: mean 0.3247, std 0.0839, min 0.0040, max 0.4680\n",
      "[INFO][mcmc] resampling walker positions\n",
      "[INFO][mcmc] running 500 walkers for 250 steps\n",
      "[INFO][mcmc] step 25: acceptance fraction: mean 0.4646, std 0.1534, min 0.0400, max 0.8400\n",
      "[INFO][mcmc] step 50: acceptance fraction: mean 0.4608, std 0.1217, min 0.1000, max 0.7800\n",
      "[INFO][mcmc] step 75: acceptance fraction: mean 0.4583, std 0.1039, min 0.1467, max 0.7200\n",
      "[INFO][mcmc] step 100: acceptance fraction: mean 0.4546, std 0.0915, min 0.1900, max 0.6800\n",
      "[INFO][mcmc] step 125: acceptance fraction: mean 0.4512, std 0.0834, min 0.1760, max 0.6320\n",
      "[INFO][mcmc] step 150: acceptance fraction: mean 0.4494, std 0.0764, min 0.2133, max 0.6333\n",
      "[INFO][mcmc] step 175: acceptance fraction: mean 0.4463, std 0.0714, min 0.2000, max 0.6171\n",
      "[INFO][mcmc] step 200: acceptance fraction: mean 0.4432, std 0.0669, min 0.2000, max 0.6200\n",
      "[INFO][mcmc] step 225: acceptance fraction: mean 0.4426, std 0.0623, min 0.2267, max 0.6133\n",
      "[INFO][mcmc] step 250: acceptance fraction: mean 0.4417, std 0.0594, min 0.2520, max 0.6120\n",
      "[INFO][mcmc] burn-in complete, starting production\n",
      "[INFO][mcmc] running 500 walkers for 500 steps\n",
      "[INFO][mcmc] step 50: acceptance fraction: mean 0.4188, std 0.1057, min 0.0600, max 0.6800\n",
      "[INFO][mcmc] step 100: acceptance fraction: mean 0.4233, std 0.0813, min 0.1200, max 0.6500\n",
      "[INFO][mcmc] step 150: acceptance fraction: mean 0.4250, std 0.0698, min 0.1733, max 0.5933\n",
      "[INFO][mcmc] step 200: acceptance fraction: mean 0.4262, std 0.0616, min 0.2350, max 0.5850\n",
      "[INFO][mcmc] step 250: acceptance fraction: mean 0.4275, std 0.0556, min 0.2160, max 0.5800\n",
      "[INFO][mcmc] step 300: acceptance fraction: mean 0.4275, std 0.0497, min 0.2467, max 0.5700\n",
      "[INFO][mcmc] step 350: acceptance fraction: mean 0.4279, std 0.0455, min 0.2600, max 0.5429\n",
      "[INFO][mcmc] step 400: acceptance fraction: mean 0.4267, std 0.0433, min 0.2700, max 0.5325\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('cache/mcmc_chain.hdf'):\n",
    "    os.remove(\"cache/mcmc_chain.hdf\")\n",
    "! /usr/local/Cellar/python/3.6.3/bin/python3 -m src.mcmc --nwalkers 500 --nburnsteps 500 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "src.Initialize()\n",
    "from src import mcmc\n",
    "chain = mcmc.Chain()\n",
    "MCMCSamples = chain.load()\n",
    "\n",
    "TransformedSamples = np.copy(MCMCSamples)\n",
    "TransformedSamples[:,0] = MCMCSamples[:,0] * MCMCSamples[:,1]\n",
    "TransformedSamples[:,1] = MCMCSamples[:,0] - MCMCSamples[:,0] * MCMCSamples[:,1]\n",
    "TransformedSamples[:,2] = MCMCSamples[:,2]\n",
    "TransformedSamples[:,3] = MCMCSamples[:,3]\n",
    "TransformedSamples[:,4] = MCMCSamples[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /usr/local/Cellar/python/3.6.3/bin/python3 -m src.plots posterior gp diag_emu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: adding all sorts of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with chain.dataset() as d:\n",
    "    W = d.shape[0]     # number of walkers\n",
    "    S = d.shape[1]     # number of steps\n",
    "    N = d.shape[2]     # number of paramters\n",
    "    T = int(S / 200)   # \"thinning\"\n",
    "    A = 20 / W\n",
    "    figure, axes = plt.subplots(figsize = (15, 2 * N), ncols = 1, nrows = N)\n",
    "    for i, ax in enumerate(axes):\n",
    "        for j in range(0, W):\n",
    "            ax.plot(range(0, S, T), d[j, ::T, i], alpha = A)\n",
    "    plt.tight_layout(True)\n",
    "    plt.savefig('plots/MCMCSamples.pdf', dpi = 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDimension = len(AllData[\"labels\"])\n",
    "Ranges = np.array(AllData[\"ranges\"]).T\n",
    "figure, axes = plt.subplots(figsize = (3 * NDimension, 3 * NDimension), ncols = NDimension, nrows = NDimension)\n",
    "Names = AllData[\"labels\"]\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        if i==j:\n",
    "            ax.hist(MCMCSamples[:,i], bins=50,\n",
    "                    range=Ranges[:,i], histtype='step', color='green')\n",
    "            ax.set_xlabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "        if i>j:\n",
    "            ax.hist2d(MCMCSamples[:, j], MCMCSamples[:, i], \n",
    "                      bins=50, range=[Ranges[:,j], Ranges[:,i]], \n",
    "                      cmap='Greens')\n",
    "            ax.set_xlabel(Names[j])\n",
    "            ax.set_ylabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "            ax.set_ylim(*Ranges[:,i])\n",
    "        if i<j:\n",
    "            ax.axis('off')\n",
    "plt.tight_layout(True)\n",
    "plt.savefig('plots/Correlation.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDimension = 5\n",
    "Ranges = np.array(AllData[\"ranges\"]).T\n",
    "figure, axes = plt.subplots(figsize = (15, 15), ncols = NDimension, nrows = NDimension)\n",
    "Names = [r\"$A$\", r\"$C$\", r\"$B$\", r\"$D$\", r\"$Q$\", r\"$P_6$\"]\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        if i==j:\n",
    "            ax.hist(TransformedSamples[:,i], bins=50,\n",
    "                    range=Ranges[:,i], histtype='step')\n",
    "            ax.set_xlabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "        if i>j:\n",
    "            ax.hist2d(TransformedSamples[:, j], TransformedSamples[:, i], \n",
    "                      bins=50, range=[Ranges[:,j], Ranges[:,i]], \n",
    "                      cmap='Blues')\n",
    "            ax.set_xlabel(Names[j])\n",
    "            ax.set_ylabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "            ax.set_ylim(*Ranges[:,i])\n",
    "        if i<j:\n",
    "            ax.axis('off')\n",
    "plt.tight_layout(True)\n",
    "plt.savefig('plots/TransformedCorrelation.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Examples = MCMCSamples[ np.random.choice(range(len(MCMCSamples)), 2500), :]\n",
    "\n",
    "TempPrediction = {\"AuAu200\": EmulatorAuAu200.predict(Examples),\n",
    "                 \"PbPb2760\": EmulatorPbPb2760.predict(Examples),\n",
    "                 \"PbPb5020\": EmulatorPbPb5020.predict(Examples)}\n",
    "\n",
    "SystemCount = len(AllData[\"systems\"])\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * SystemCount), ncols = 2, nrows = SystemCount)\n",
    "\n",
    "for s1 in range(0, SystemCount):\n",
    "    for s2 in range(0, 2):\n",
    "        axes[s1][s2].set_xlabel(r\"$p_{T}$\")\n",
    "        axes[s1][s2].set_ylabel(r\"$R_{AA}$\")\n",
    "        \n",
    "        S1 = AllData[\"systems\"][s1]\n",
    "        O  = AllData[\"observables\"][0][0]\n",
    "        S2 = AllData[\"observables\"][0][1][s2]\n",
    "        \n",
    "        DX = AllData[\"data\"][S1][O][S2]['x']\n",
    "        DY = AllData[\"data\"][S1][O][S2]['y']\n",
    "        DE = np.sqrt(AllData[\"data\"][S1][O][S2]['yerr']['stat'][:,0]**2 + AllData[\"data\"][S1][O][S2]['yerr']['sys'][:,0]**2)\n",
    "                \n",
    "        for i, y in enumerate(TempPrediction[S1][O][S2]):\n",
    "            axes[s1][s2].plot(DX, y, 'b-', alpha=0.005, label=\"Posterior\" if i==0 else '')\n",
    "        axes[s1][s2].errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "plt.tight_layout(True)\n",
    "figure.savefig('plots/ObservablePosterior.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Examples = AllData[\"design\"]\n",
    "\n",
    "TempPrediction = {\"AuAu200\": EmulatorAuAu200.predict(Examples),\n",
    "                 \"PbPb2760\": EmulatorPbPb2760.predict(Examples),\n",
    "                 \"PbPb5020\": EmulatorPbPb5020.predict(Examples)}\n",
    "\n",
    "SystemCount = len(AllData[\"systems\"])\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * SystemCount), ncols = 2, nrows = SystemCount)\n",
    "\n",
    "for s1 in range(0, SystemCount):\n",
    "    for s2 in range(0, 2):\n",
    "        axes[s1][s2].set_xlabel(r\"$p_{T}$\")\n",
    "        axes[s1][s2].set_ylabel(r\"$R_{AA}$\")\n",
    "        \n",
    "        S1 = AllData[\"systems\"][s1]\n",
    "        O  = AllData[\"observables\"][0][0]\n",
    "        S2 = AllData[\"observables\"][0][1][s2]\n",
    "        \n",
    "        DX = AllData[\"data\"][S1][O][S2]['x']\n",
    "        DY = AllData[\"data\"][S1][O][S2]['y']\n",
    "        DE = np.sqrt(AllData[\"data\"][S1][O][S2]['yerr']['stat'][:,0]**2 + AllData[\"data\"][S1][O][S2]['yerr']['sys'][:,0]**2)\n",
    "                \n",
    "        for i, y in enumerate(TempPrediction[S1][O][S2]):\n",
    "            axes[s1][s2].plot(DX, y, 'b-', alpha=0.1, label=\"Posterior\" if i==0 else '')\n",
    "        axes[s1][s2].errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "plt.tight_layout(True)\n",
    "figure.savefig('plots/PredictedDesign.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TempPrediction = AllData[\"model\"]\n",
    "\n",
    "SystemCount = len(AllData[\"systems\"])\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * SystemCount), ncols = 2, nrows = SystemCount)\n",
    "\n",
    "for s1 in range(0, SystemCount):\n",
    "    for s2 in range(0, 2):\n",
    "        axes[s1][s2].set_xlabel(r\"$p_{T}$\")\n",
    "        axes[s1][s2].set_ylabel(r\"$R_{AA}$\")\n",
    "        \n",
    "        S1 = AllData[\"systems\"][s1]\n",
    "        O  = AllData[\"observables\"][0][0]\n",
    "        S2 = AllData[\"observables\"][0][1][s2]\n",
    "        \n",
    "        DX = AllData[\"data\"][S1][O][S2]['x']\n",
    "        DY = AllData[\"data\"][S1][O][S2]['y']\n",
    "        DE = np.sqrt(AllData[\"data\"][S1][O][S2]['yerr']['stat'][:,0]**2 + AllData[\"data\"][S1][O][S2]['yerr']['sys'][:,0]**2)\n",
    "                \n",
    "        for i, y in enumerate(TempPrediction[S1][O][S2]['Y']):\n",
    "            axes[s1][s2].plot(DX, y, 'b-', alpha=0.1, label=\"Posterior\" if i==0 else '')\n",
    "        axes[s1][s2].errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "plt.tight_layout(True)\n",
    "figure.savefig('plots/Design.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close all plots to save memory\n",
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
